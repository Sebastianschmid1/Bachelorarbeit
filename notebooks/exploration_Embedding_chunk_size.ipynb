{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "import time\n",
    "from Utils.embedding import plot_results\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "test_text_embeddings = [\n",
    "        \"Für was steht UNA?\",\n",
    "        \"Für was steht UNH?\",\n",
    "        \"Für was steht DTM?\",\n",
    "        \"Für was steht RFF?\",\n",
    "        \"Für was steht NAD?\",\n",
    "        \"Für was steht LIN?\",\n",
    "        \"Für was steht BGM?\",\n",
    "        \"Was ist Bezeichnung für Trennzeichen?\",\n",
    "        \"Was ist Bezeichnung für Gesetzlich vorgeschriebener Text?\",\n",
    "        \"Was ist Bezeichnung für Nachrichtendatum?\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messung für \"text-embedding-3-large\" durchläufen mit 10 Fragen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_9752\\1462801016.py:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  \"pdfs\\MIG_VDA4938T2_eingehend_v.2.6_DE.pdf\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "Segmente  \n",
      " \n",
      "Bez = Objekt-Bezeichner, Nr = Laufende Segmentnumme r im Guide, MaxWdh = Maximale Wiederholung der Segm ente/Gruppen  \n",
      "St = Status, M=Muss, C=Kann, R=Gefordert, O=Optiona l, D=Abhängig  von , A=Empfohlen, N=Nicht benutzt  \n",
      "  Seite:12 /96  \n",
      " \n",
      " Zähler     Nr  Bez   St  MaxWdh  Ebene  Name  \n",
      "  \n",
      " 0000 1   UNA   O 1 0  Trennzeichen-Vorgabe  \n",
      "  \n",
      " Standard  Implementierung  \n",
      "Bez  Name  St  Format   St  Format Beispiel  Anwendung / Bemerkung  \n",
      "UNA       UNA  \n",
      "UNA1  Gruppendatenelement-  \n",
      "Trennzeichen  M an1   M an1 : Doppelpunkt  \n",
      "UNA2  Segment-Bezeichner- und  \n",
      "Datenelement -Trennzeichen  M an1   M an1 + Pluszeichen  \n",
      "UNA3  Dezimalzeichen  M an1   M an1  . Punkt  \n",
      "UNA4  Freigabezeichen  M an1   M an1  ? Fragezeichen  \n",
      "UNA5  Reserviert für spätere  \n",
      "Verwendung  M an1   M an1  Leerzeichen  \n",
      "UNA6  Segment -Endezeichen  M an1   M an1  ' Hochkomma  \n",
      " Beispiel  UNA:+.? '\n",
      "Das erzeugen der Embeddings hat 66.0217273235321 Sekunden gedauert.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", chunk_size=1)\n",
    "t1 = time.time()\n",
    "for i in range(1):\n",
    "\n",
    "    results = []\n",
    "    loader = PyPDFLoader(\n",
    "        \"pdfs\\MIG_VDA4938T2_eingehend_v.2.6_DE.pdf\",\n",
    "        extract_images=False,\n",
    "    )\n",
    "    pages = loader.load_and_split()\n",
    "    faiss_index = FAISS.from_documents(pages, embeddings)\n",
    "print(f\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "print(faiss_index.similarity_search_with_score(test_text_embeddings[0], 1)[0][0].page_content)\n",
    "print(f\"Das erzeugen der Embeddings hat {time.time() - t1} Sekunden gedauert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messung für \"text-embedding-3-small\" durchläufen mit 10 Fragen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_9752\\660202543.py:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  \"pdfs\\MIG_VDA4938T2_eingehend_v.2.6_DE.pdf\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "Segmente  \n",
      " \n",
      "Bez = Objekt-Bezeichner, Nr = Laufende Segmentnumme r im Guide, MaxWdh = Maximale Wiederholung der Segm ente/Gruppen  \n",
      "St = Status, M=Muss, C=Kann, R=Gefordert, O=Optiona l, D=Abhängig  von , A=Empfohlen, N=Nicht benutzt  \n",
      "  Seite:12 /96  \n",
      " \n",
      " Zähler     Nr  Bez   St  MaxWdh  Ebene  Name  \n",
      "  \n",
      " 0000 1   UNA   O 1 0  Trennzeichen-Vorgabe  \n",
      "  \n",
      " Standard  Implementierung  \n",
      "Bez  Name  St  Format   St  Format Beispiel  Anwendung / Bemerkung  \n",
      "UNA       UNA  \n",
      "UNA1  Gruppendatenelement-  \n",
      "Trennzeichen  M an1   M an1 : Doppelpunkt  \n",
      "UNA2  Segment-Bezeichner- und  \n",
      "Datenelement -Trennzeichen  M an1   M an1 + Pluszeichen  \n",
      "UNA3  Dezimalzeichen  M an1   M an1  . Punkt  \n",
      "UNA4  Freigabezeichen  M an1   M an1  ? Fragezeichen  \n",
      "UNA5  Reserviert für spätere  \n",
      "Verwendung  M an1   M an1  Leerzeichen  \n",
      "UNA6  Segment -Endezeichen  M an1   M an1  ' Hochkomma  \n",
      " Beispiel  UNA:+.? '\n",
      "Das erzeugen der Embeddings hat 52.41604828834534 Sekunden gedauert.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", chunk_size=2)\n",
    "t1 = time.time()\n",
    "for i in range(1):\n",
    "\n",
    "    results = []\n",
    "    loader = PyPDFLoader(\n",
    "        \"pdfs\\MIG_VDA4938T2_eingehend_v.2.6_DE.pdf\",\n",
    "        extract_images=False,\n",
    "    )\n",
    "    pages = loader.load_and_split()\n",
    "    faiss_index = FAISS.from_documents(pages, embeddings)\n",
    "print(f\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "print(faiss_index.similarity_search_with_score(test_text_embeddings[0], 1)[0][0].page_content)\n",
    "print(f\"Das erzeugen der Embeddings hat {time.time() - t1} Sekunden gedauert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messung für \"text-embedding-ada-002\" durchläufen mit 10 Fragen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_9752\\2267584136.py:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  \"pdfs\\MIG_VDA4938T2_eingehend_v.2.6_DE.pdf\",\n",
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_9752\\2267584136.py:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  \"pdfs\\MIG_VDA4938T2_eingehend_v.2.6_DE.pdf\",\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "range() arg 3 must not be zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m     loader \u001b[38;5;241m=\u001b[39m PyPDFLoader(\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdfs\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMIG_VDA4938T2_eingehend_v.2.6_DE.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m         extract_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m     )\n\u001b[0;32m     10\u001b[0m     pages \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_and_split()\n\u001b[1;32m---> 11\u001b[0m     faiss_index \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     14\u001b[0m     faiss_index\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(test_text_embeddings[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     16\u001b[0m     ]\u001b[38;5;241m.\u001b[39mpage_content\n\u001b[0;32m     17\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sebas\\repros\\Bachelorarbeit\\venv\\Lib\\site-packages\\langchain_core\\vectorstores.py:550\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    549\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\repros\\Bachelorarbeit\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:930\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    911\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m    912\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 930\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m    932\u001b[0m         texts,\n\u001b[0;32m    933\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    938\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sebas\\repros\\Bachelorarbeit\\venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:532\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\repros\\Bachelorarbeit\\venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:332\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    330\u001b[0m         _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tokens), _chunk_size)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 332\u001b[0m     _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n",
      "\u001b[1;31mValueError\u001b[0m: range() arg 3 must not be zero"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", chunk_size=0.5)\n",
    "t1 = time.time()\n",
    "for i in range(1):\n",
    "\n",
    "    results = []\n",
    "    loader = PyPDFLoader(\n",
    "        \"pdfs\\MIG_VDA4938T2_eingehend_v.2.6_DE.pdf\",\n",
    "        extract_images=False,\n",
    "    )\n",
    "    pages = loader.load_and_split()\n",
    "    faiss_index = FAISS.from_documents(pages, embeddings)\n",
    "print(f\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "print(\n",
    "    faiss_index.similarity_search_with_score(test_text_embeddings[0], 1)[0][\n",
    "        0\n",
    "    ].page_content\n",
    ")\n",
    "print(f\"Das erzeugen der Embeddings hat {time.time() - t1} Sekunden gedauert.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
