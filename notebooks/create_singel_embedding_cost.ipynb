{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_16208\\1526657393.py:12: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  input_texts = \"Diese Arbeit ist unter Anleitung von Prof. Dr. MAX Muster an der Hochschule Muster im Rahmen einer Bachelorarbeit verfasst worden. Das Ziel der Arbeit ist eine Beispielimplementierung einer Application zu erstellen, die PDF Dokumente mittels semantischer Suche und eines Chatbots, scannen kann und anschließen passende Antworten zurückgibt. In unserer zunehmend vernetzten Welt spielt die Effizienz des Informationsaustausches eine entscheidende Rolle in der Wettbewerbsfähigkeit industrieller Lieferketten. Die Fähigkeit, digitale Daten schnell und zuverlässig zu verarbeiten, ist zu einem Eckpfeiler organisatorischer Adaption und Innovation geworden \\cite{1}. Die Automobilindustrie steht in diesem Kontext exemplarisch für die Herausforderungen und Möglichkeiten, die mit der digitalen Transformation einhergehen. Ein zentrales Element dieser Transformation ist die Implementierung von Industriestandards, wie sie im VDA-Standard zum Vorschein kommen, der die Kommunikationsprozesse zwischen Automobilproduzenten und Lieferanten entscheidend prägt \\cite{2}. Diese Standards wurden entwickelt, um die Übermittlung und das Verständnis von Informationen zu vereinheitlichen und somit die Effizienz interorganisationaler Koordinationsprozesse zu verbessern. Nichtsdestotrotz bleiben in der operativen Umsetzung des EDIFACT-Standards Herausforderungen bestehen, da die Komplexität der Lieferketten und die Variabilität ihrer Strukturen zu Interpretationsdifferenzen und operativen Schwierigkeiten führen können \\cite{3}. Der Bedarf an fortschrittlichen Lösungen zur Interpretation und Verarbeitung dieser komplexen Informationsgebilde ist evident. In diesem Kontext setzt sich die vorliegende Arbeit mit der Entwicklung und Implementierung von Künstlicher Intelligenz (KI) auseinander, mit einem speziellen Fokus auf der Anwendung KI-basierter Sprachmodelle zur Verarbeitung und Analyse von umfangreichen Leitliniendokumenten.Die Untersuchung wird sich insbesondere mit den technischen Anforderungen, dem erforderlichen Aufwand und den Charakteristika einer solchen KI-Architektur befassen. Darüber hinaus soll erörtert werden, wie diese Technologien die Effektivität von Informationsflüssen innerhalb komplexer Lieferketten verbessern können \\cite{4}. Ein weiterer Aspekt dieser Arbeit betrachtet die praktischen Schwierigkeiten, die beim Umgang mit unstrukturierten Dokumenten wie PDFs entstehen, welche in der Lieferkette häufig vorkommen. Es wird untersucht, wie diese in ein Format überführt werden können, das von KI-Modellen erfasst und interpretiert werden kann, um so einen Mehrwert für die Datenanalyse und Entscheidungsfindung zu schaffen \\cite{5}. Um die Qualität der generierten Antworten zu optimieren und die Komplexität der Arbeit zu reduzieren, wird das Chat-Modell ChatGPT-4 verwendet, das im Vergleich zu seinem Vorgänger 3.5-Turbo signifikante Verbesserungen aufweist, wie in anderen Studien belegt wird\\cite{20}. Die vorliegende Arbeit verfolgt das Ziel, einen umfassenden Überblick über die technischen, praktischen und insbesondere zeitlichen Aspekte der Implementierung eines RAG-Systems zu geben. Darüber hinaus soll aufgezeigt werden, welchen Nutzen ein solches System für kleine Unternehmen hat. Im Folgenden werden zunächst die Grundlagen und verwandte Arbeiten, verwendeten Methoden, Vorgehensweisen und verwendete Software erläutert. Anschließend erörtern wir unsere Erkenntnisse und visualisieren sie. Im letzten Teil dieser Arbeit werden Erkenntnisse diskutiert, Verbesserungsmöglichkeiten und darüber zukünftige Verbesserungen und Erweiterungen mit dieser Arbeit zu motivieren.\"\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "embedding_list = []\n",
    "input_texts = \"Diese Arbeit ist unter Anleitung von Prof. Dr. MAX Muster an der Hochschule Muster im Rahmen einer Bachelorarbeit verfasst worden. Das Ziel der Arbeit ist eine Beispielimplementierung einer Application zu erstellen, die PDF Dokumente mittels semantischer Suche und eines Chatbots, scannen kann und anschließen passende Antworten zurückgibt. In unserer zunehmend vernetzten Welt spielt die Effizienz des Informationsaustausches eine entscheidende Rolle in der Wettbewerbsfähigkeit industrieller Lieferketten. Die Fähigkeit, digitale Daten schnell und zuverlässig zu verarbeiten, ist zu einem Eckpfeiler organisatorischer Adaption und Innovation geworden \\cite{1}. Die Automobilindustrie steht in diesem Kontext exemplarisch für die Herausforderungen und Möglichkeiten, die mit der digitalen Transformation einhergehen. Ein zentrales Element dieser Transformation ist die Implementierung von Industriestandards, wie sie im VDA-Standard zum Vorschein kommen, der die Kommunikationsprozesse zwischen Automobilproduzenten und Lieferanten entscheidend prägt \\cite{2}. Diese Standards wurden entwickelt, um die Übermittlung und das Verständnis von Informationen zu vereinheitlichen und somit die Effizienz interorganisationaler Koordinationsprozesse zu verbessern. Nichtsdestotrotz bleiben in der operativen Umsetzung des EDIFACT-Standards Herausforderungen bestehen, da die Komplexität der Lieferketten und die Variabilität ihrer Strukturen zu Interpretationsdifferenzen und operativen Schwierigkeiten führen können \\cite{3}. Der Bedarf an fortschrittlichen Lösungen zur Interpretation und Verarbeitung dieser komplexen Informationsgebilde ist evident. In diesem Kontext setzt sich die vorliegende Arbeit mit der Entwicklung und Implementierung von Künstlicher Intelligenz (KI) auseinander, mit einem speziellen Fokus auf der Anwendung KI-basierter Sprachmodelle zur Verarbeitung und Analyse von umfangreichen Leitliniendokumenten.Die Untersuchung wird sich insbesondere mit den technischen Anforderungen, dem erforderlichen Aufwand und den Charakteristika einer solchen KI-Architektur befassen. Darüber hinaus soll erörtert werden, wie diese Technologien die Effektivität von Informationsflüssen innerhalb komplexer Lieferketten verbessern können \\cite{4}. Ein weiterer Aspekt dieser Arbeit betrachtet die praktischen Schwierigkeiten, die beim Umgang mit unstrukturierten Dokumenten wie PDFs entstehen, welche in der Lieferkette häufig vorkommen. Es wird untersucht, wie diese in ein Format überführt werden können, das von KI-Modellen erfasst und interpretiert werden kann, um so einen Mehrwert für die Datenanalyse und Entscheidungsfindung zu schaffen \\cite{5}. Um die Qualität der generierten Antworten zu optimieren und die Komplexität der Arbeit zu reduzieren, wird das Chat-Modell ChatGPT-4 verwendet, das im Vergleich zu seinem Vorgänger 3.5-Turbo signifikante Verbesserungen aufweist, wie in anderen Studien belegt wird\\cite{20}. Die vorliegende Arbeit verfolgt das Ziel, einen umfassenden Überblick über die technischen, praktischen und insbesondere zeitlichen Aspekte der Implementierung eines RAG-Systems zu geben. Darüber hinaus soll aufgezeigt werden, welchen Nutzen ein solches System für kleine Unternehmen hat. Im Folgenden werden zunächst die Grundlagen und verwandte Arbeiten, verwendeten Methoden, Vorgehensweisen und verwendete Software erläutert. Anschließend erörtern wir unsere Erkenntnisse und visualisieren sie. Im letzten Teil dieser Arbeit werden Erkenntnisse diskutiert, Verbesserungsmöglichkeiten und darüber zukünftige Verbesserungen und Erweiterungen mit dieser Arbeit zu motivieren.\"\n",
    "\n",
    "\n",
    "def get_embedding(input_text):\n",
    "    return client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=input_text,\n",
    "        encoding_format=\"float\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erzeuge aus der liste \"input_texts\" embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_embedding(input_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speicher der Ergebnisse in ein Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding.data[0].embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
